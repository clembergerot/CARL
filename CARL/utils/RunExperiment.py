# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/utils/20_RunExperiment.ipynb.

# %% auto 0
__all__ = ['RunExperiment']

# %% ../../nbs/utils/20_RunExperiment.ipynb 4
import numpy as np
import pandas as pd
from datetime import datetime

# from envs.TwoArmedBandit import TwoArmedBandit
# from agents.SimpleConf import SimpleConf

# %% ../../nbs/utils/20_RunExperiment.ipynb 5
class RunExperiment(object):
    """ 
    Class for running simulations with CARL and saving results.
    """
    
    def __init__(self, params, path, version):
        self.params = params  # params dict
        self.p0 = params['p0']  # reward probability for arm 0
        self.p1 = params['p1']  # reward probability for arm 1
        self.rew = params['rew']  # reward value
        self.pun = params['pun']  # punishment value
        self.n_trials = params['n_trials']  # number of trials
        self.n_simu = params['n_simu']  # number of simulations
        self.alphaD = params['alphaD']  # disc learning rate
        self.alphaC = params['alphaC']  # conf learning rate
        self.beta = params['beta']  # inverse temperature
        self.n_agents = params['n_agents']  # group size
        self.bias_strength = params['bias_strength']  # bias strength
        self.task_name = params['task_name']  # resource scarcity
        self.path = path  # path to save data
        self.version = version  # data version
        
    def SaveParams(self):   
        """Saves simulation parameters and outputs params dataframe."""
        # Create multiindex for params dataframe
        miparams = pd.MultiIndex.from_product([self.task_name, self.n_agents, self.bias_strength], 
                                              names=['scarcity', 'group_size', 'bias_strength'])
        # Create dataframe
        lent = len(self.task_name)
        lena = len(self.n_agents)
        lens = len(self.bias_strength)
        params_array = np.zeros((lent * lena * lens, 7))
        params_array[:, 0] = np.array(self.alphaC * (lena * lent)) 
        params_array[:, 1] = np.array(self.alphaD * (lena * lent))
        params_array[:, 2] = self.beta
        params_array[:, 3] = np.repeat(self.p0, lena * lens)
        params_array[:, 4] = np.repeat(self.p1, lena * lens)
        params_array[:, 5] = self.n_simu
        params_array[:, 6] = self.n_trials
        
        # Create column labels
        index_col = [["alpha_C", "alpha_D", "beta", "p0", "p1", "n_simu", "n_trials"]]
        
        # Make df
        dfparams = pd.DataFrame(params_array, index=miparams, columns=index_col)
        
        # Save df to hdf5 file
        dfparams.to_hdf(self.path+"data_exp_"+self.version+".h5", "params", mode='w')
        return dfparams
    
    def RunAndSave(self):
        """Runs experiment according to params and saves results."""
        lenb = len(self.bias_strength)
        lent = len(self.task_name)
        
        for a in range(lenb):  # loop on bias types
        
            for i, n in enumerate(self.n_agents):
                # Make df to store rewards, choices, Q-values at each trial
                iterables_row = [[str(j) for j in range(self.n_simu)], 
                                 [str(j) for j in range(self.n_trials)], 
                                 [str(j) for j in range(n)]]
                iterables_col = [["R", "C", "Q0", "Q1"], self.task_name]

                index_row = pd.MultiIndex.from_product(iterables_row, 
                                                       names=["simus", "trials", "agent"])
                index_col = pd.MultiIndex.from_product(iterables_col, 
                                                       names=["variables", "scarcity"])
            
                data = np.zeros((self.n_simu * self.n_trials * n, 
                                lent * 4))
            
                for s in range(lent):  # loop on resource scarcities
                    start = datetime.now()  # to measure simulation duration
                    
                    # Define a two-armed bandit task
                    task = TwoArmedBandit(self.p0[s], self.p1[s], self.rew, self.pun)
                    
                    # Indices for rewards, choices, q-values in dataframe
                    R_idx = int(0 + s) 
                    C_idx = int(lent + s)
                    Q0_idx = int(2 * lent + s)
                    Q1_idx = int(3 * lent + s)
            
                    pars_agent = np.array([self.alphaC[a]/n, self.alphaD[a]/n, self.beta])  # params:
                    # confirmatory learning rate, disconfirmatory learning rate (both
                    # scaled by 1/n), inv temperature
                    pars_simu = np.row_stack((pars_agent,) * n)  # all the agents in the
                    # group have the same params
                    agents = SimpleConf(pars_simu)
                    G_att = agents.connect_agents_full()  # agents are fully connected
                    for simu in range(self.n_simu):  # loop on simulations
                        Qtable = np.zeros((n, 2))  # init Q-table
                        for trial in range(self.n_trials):  # loop on trials
                            row_idx = int(simu * self.n_trials * n + trial * n) 
                            choices = agents.all_take_action(Qtable)  # each agent chooses one
                            # bandit according to its Q-table
                            data[row_idx:row_idx+n, C_idx] = choices
                            payoffs = task.return_payoffs(choices)  # each agent gets
                            # corresponding payoffs
                            data[row_idx:row_idx+n, R_idx] = payoffs
                            Qtable = agents.update_Qvalues(G_att, choices, payoffs, Qtable)
                            data[row_idx:row_idx+n, Q0_idx] = Qtable[:, 0]
                            data[row_idx:row_idx+n, Q1_idx] = Qtable[:, 1]
                            # Qtables are updated according to Social RL model
                    
                    # Print statement that simulation is finished with simulation duration
                    print("Group "+str(n)+", bias strength "+self.bias_strength[a]+", task "
                          +self.task_name[s]+" finished, time="+str(datetime.now()-start))
                
                # Make data df
                data_df = pd.DataFrame(data, index=index_row, columns=index_col)
                group = '/groupsize'+str(n)
                key = '/bs'+self.bias_strength[a]
                # Save data to hdf5 file
                data_df.to_hdf(self.path+"data_expe4_"+self.version+".h5", group+key, mode='a')
                
        return data_df
